# Gunicorn YapÄ±landÄ±rmasÄ± - DigitalOcean Droplet Ä°Ã§in Optimize
import multiprocessing
import os

bind = f"0.0.0.0:{os.environ.get('FLASK_PORT', '8000')}"

# Worker AyarlarÄ± - 32GB RAM iÃ§in optimize
workers = 2  # 1'den 2'ye Ã§Ä±karÄ±ldÄ± (daha iyi throughput)
threads = 4  # Thread bazlÄ± eÅŸzamanlÄ±lÄ±k
worker_class = "gthread"  # Thread destekli worker

# Timeout AyarlarÄ± - Ã–NEMLÄ°! (Nginx ile uyumlu) - Optimize edildi
timeout = 90  # Worker timeout (600'tan 90'a dÃ¼ÅŸÃ¼rÃ¼ldÃ¼ - daha hÄ±zlÄ± failover)
graceful_timeout = 30  # Graceful shutdown timeout (300'den 30'a dÃ¼ÅŸÃ¼rÃ¼ldÃ¼)
keepalive = 10  # Keep-alive baÄŸlantÄ±larÄ± (5'ten 10'a Ã§Ä±karÄ±ldÄ±)

# Model YÃ¼kleme Ä°Ã§in Preload
preload_app = True  # Modeli bir kez yÃ¼kle, tÃ¼m worker'larda paylaÅŸ

# Logging - systemd journal ile uyumlu
accesslog = "-"  # stdout'a yaz
errorlog = "-"
loglevel = "info"
capture_output = True
enable_stdio_inheritance = True

# HafÄ±za YÃ¶netimi - DigitalOcean iÃ§in Ã¶nemli
max_requests = 100  # Worker'Ä± N istekten sonra yeniden baÅŸlat (50'den 100'e Ã§Ä±karÄ±ldÄ±)
max_requests_jitter = 20  # Rastgele jitter ekle (10'dan 20'ye Ã§Ä±karÄ±ldÄ±)

# Performans - Linux iÃ§in
worker_tmp_dir = "/dev/shm"  # RAM disk kullan

def on_starting(server):
    print("ğŸš€ Gunicorn baÅŸlatÄ±lÄ±yor...")
    print("ğŸ“¦ preload_app=True - Modeller yÃ¼klenecek...")

def post_fork(server, worker):
    print(f"ğŸ‘· Worker {worker.pid} baÅŸlatÄ±ldÄ±")

def worker_exit(server, worker):
    print(f"ğŸ›‘ Worker {worker.pid} sonlandÄ±rÄ±ldÄ±")
